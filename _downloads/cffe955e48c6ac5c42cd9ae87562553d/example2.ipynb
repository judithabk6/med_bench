{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Flexible use of an estimator in `med_bench`\n\nIn this example, we illustrate the different parameter choices when using an estimator. We can fit the model with different models for the estimation of nuisance parameters. It is also possible to use cross-fitting to compensate the estimation bias due to AI models. \n\nWe will also show bootstrap to obtain confidence intervals, and the different estimation variants regarding the choice of nuisance functions to estimate and the way to handle integration over the possible mediator values (not implemented yet in this example, stay tuned for more).\n\n\nAs in the previous example, we simulate data.\n\n## Data simulation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from med_bench.get_simulated_data import simulate_data\nfrom med_bench.estimation.mediation_mr import MultiplyRobust\n\nimport numpy as np\nfrom numpy.random import default_rng\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegressionCV, RidgeCV\n\nALPHAS = np.logspace(-5, 5, 8)\nCV_FOLDS = 5\nTINY = 1.0e-12\n\nrg = default_rng(42)\n\n(x, t, m, y, total, theta_1, theta_0,\n delta_1, delta_0, p_t, th_p_t_mx) = \\\n    simulate_data(n=500,\n                  rg=rg,\n                  mis_spec_m=False,\n                  mis_spec_y=False,\n                  dim_x=5,\n                  dim_m=1,\n                  seed=5,\n                  type_m='continuous',\n                  sigma_y=0.5,\n                  sigma_m=0.5,\n                  beta_t_factor=0.2,\n                  beta_m_factor=5)\nprint_effects = ('total effect: {:.2f}\\n'\n                'direct effect: {:.2f}\\n'\n                'indirect effect: {:.2f}')\nprint('True effects')\nprint(print_effects.format(total, theta_1, delta_0))\n\nres_list = list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## With simple linear models, without regularization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# define nuisance estimators with scikit-learn, without regularization\nclf = LogisticRegressionCV(random_state=42, Cs=[np.inf], cv=CV_FOLDS)\nreg = RidgeCV(alphas=[TINY], cv=CV_FOLDS)\nestimator = MultiplyRobust(\n    clip=1e-6, trim=0, \n    prop_ratio=\"treatment\",\n    normalized=True,\n    regressor=reg,\n    classifier=clf,\n    integration=\"implicit\",\n)\nestimator.fit(t, m, x, y)\ncausal_effects_noreg = estimator.estimate(t.ravel(), m, x, y.ravel())\nprint(print_effects.format(causal_effects_noreg[\"total_effect\"],\n                           causal_effects_noreg[\"direct_effect_treated\"],\n                           causal_effects_noreg[\"indirect_effect_control\"]))\nres_list.append(['without regularization',\n                 causal_effects_noreg[\"total_effect\"],\n                 causal_effects_noreg[\"direct_effect_treated\"],\n                 causal_effects_noreg[\"indirect_effect_control\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## With simple linear models, with regularization \nRegularization hyperparameters chosen by gridsearch and crossvalidation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf = LogisticRegressionCV(random_state=42, Cs=ALPHAS, cv=CV_FOLDS)\nreg = RidgeCV(alphas=ALPHAS, cv=CV_FOLDS)\nestimator = MultiplyRobust(\n    clip=1e-6, trim=0, \n    prop_ratio=\"treatment\",\n    normalized=True,\n    regressor=reg,\n    classifier=clf,\n    integration=\"implicit\",\n)\nestimator.fit(t, m, x, y)\ncausal_effects_reg = estimator.estimate(t.ravel(), m, x, y.ravel())\nprint(print_effects.format(causal_effects_reg[\"total_effect\"],\n                           causal_effects_reg[\"direct_effect_treated\"],\n                           causal_effects_reg[\"indirect_effect_control\"]))\nres_list.append(['with regression',\n                 causal_effects_reg[\"total_effect\"],\n                 causal_effects_reg[\"direct_effect_treated\"],\n                 causal_effects_reg[\"indirect_effect_control\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## With machine learning models\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(n_estimators=100,\n                             min_samples_leaf=10,\n                             max_depth=10,\n                             random_state=25)\nreg = RandomForestRegressor(n_estimators=100,\n                            min_samples_leaf=10,\n                            max_depth=10,\n                            random_state=25)\nestimator = MultiplyRobust(\n    clip=1e-6, trim=0, \n    prop_ratio=\"treatment\",\n    normalized=True,\n    regressor=reg,\n    classifier=clf,\n    integration=\"implicit\",\n)\nestimator.fit(t, m, x, y)\ncausal_effects_forest = estimator.estimate(t.ravel(), m, x, y.ravel())\nprint(print_effects.format(causal_effects_forest[\"total_effect\"],\n                           causal_effects_forest[\"direct_effect_treated\"],\n                           causal_effects_forest[\"indirect_effect_control\"]))\nres_list.append(['with RF',\n                 causal_effects_forest[\"total_effect\"],\n                 causal_effects_forest[\"direct_effect_treated\"],\n                 causal_effects_forest[\"indirect_effect_control\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## With cross-fitting\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(n_estimators=100,\n                             min_samples_leaf=10,\n                             max_depth=10,\n                             random_state=25)\nreg = RandomForestRegressor(n_estimators=100,\n                            min_samples_leaf=10,\n                            max_depth=10,\n                            random_state=25)\nestimator = MultiplyRobust(\n    clip=1e-6, trim=0, \n    prop_ratio=\"treatment\",\n    normalized=True,\n    regressor=reg,\n    classifier=clf,\n    integration=\"implicit\",\n)\ncf_n_splits = 2\ncausal_effects_forest_cf = estimator.cross_fit_estimate(\n    t, m, x, y, n_splits=cf_n_splits)\nprint(print_effects.format(causal_effects_forest_cf[\"total_effect\"],\n                           causal_effects_forest_cf[\"direct_effect_treated\"],\n                           causal_effects_forest_cf[\"indirect_effect_control\"]))\n\nres_list.append(['with RF CF',\n                 causal_effects_forest_cf[\"total_effect\"],\n                 causal_effects_forest_cf[\"direct_effect_treated\"],\n                 causal_effects_forest_cf[\"indirect_effect_control\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results summary\nWe show the estimates from the different methods, with the vertical red line being the theoretical value. In all cases we see a slight difference with the truth.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "res_df = pd.DataFrame(res_list, \n                      columns=['method',\n                               'total_effect',\n                               'direct_effect',\n                               'indirect_effect'])\nfig, ax = plt.subplots(ncols=3, figsize=(17, 5))\nsns.pointplot(y='method', x='direct_effect', data=res_df, orient='h', ax=ax[0], join = False, color='black', estimator=np.median)\n\nax[0].set_ylabel('method', weight='bold', fontsize=15)\nax[0].set_xlabel('Direct effect', weight='bold', fontsize=15)\nax[0].axvline(x=theta_1, lw=3, color='red')\nax[1].axvline(x=delta_0, lw=3, color='red')  \nax[2].axvline(x=total, lw=3, color='red')                                                       \nsns.pointplot(y='method', x='indirect_effect', data=res_df, orient='h', ax=ax[1], join = False, color='black', estimator=np.median)\nax[1].set_ylabel('')\nax[1].set_xlabel('Indirect effect', weight='bold', fontsize=15)\nax[1].set(yticklabels=[])\nsns.pointplot(y='method', x='total_effect', data=res_df, orient='h', ax=ax[2], join = False, color='black', estimator=np.median)\nax[2].set_ylabel('')\nax[2].set_xlabel('Total effect', weight='bold', fontsize=15)\nax[2].set(yticklabels=[])\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}